<!DOCTYPE HTML>
<html>
	<head>
		<title>About me - Akshath Varugeese</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<link rel="stylesheet" href="assets/css/timeline.css" />	
	</head>
	<body class="is-preload">

		<!-- Header -->
			<section id="header">
				<header style='padding-bottom: 0px;'>
					<span class="image avatar"><img src="images/Akshath.jpg" alt="" /></span>
					<h1 id="logo" style="margin-bottom: 10px;"><a href="#">Akshath Varugeese</a></h1>
					<ul class="icons" style="margin-bottom: 0px;">
						<li><a href="https://www.linkedin.com/in/akshath-varugeese/" class="icon brands fa-linkedin"><span class="label">Facebook</span></a></li>
						<li><a href="https://www.youtube.com/channel/UCU-0H3m6JgpC6mEiy_vXELg" class="icon brands fa-youtube"><span class="label">YouTube</span></a></li>
						<li><a href="https://github.com/akshath123" class="icon brands fa-github"><span class="label">Github</span></a></li>
						<li><a href="#" class="icon fas fa-edit"><span class="label">Blog</span></a></li>						
					</ul>					
				</header>
				<nav id="nav">
					<ul>
						<li><a href="#about_me" class="active">About Me</a></li>
						<li><a href="#skills">Skills</a></li>
						<li><a href="#work_experience">Work Experience</a></li>
						<li><a href="#research_papers">Research Papers</a></li>
						<li><a href="#education">Education</a></li>
						<li><a href="#accomplishments">Accomplishments</a></li>
						<li><a href="#hobbies">Hobbies</a></li>
					</ul>
				</nav>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">

						<!-- About Me -->
							<section id="about_me">
								<div class="container">
									<header class="major" style="margin-bottom: 0px; text-align: justify;">
										<h2>Greetings!</h2>
										<p style = "margin-bottom: 20px;">About me</p>										
										I am a <b>Machine Learing</b> and <b>Computer Vision Engineer</b> based in 
										Bangalore. I am currently working in 
										<b><a href = "https://www.capillarytech.com/products/smart-store-plus/?utm_campaign=Capillary_India_Brand&utm_medium=cpc&utm_source=google&Lead_Source=Adwords&PPC&adposition=&searchkeyword=capillary&technologies&matchtype=b&device=c&locationID=1007809&Campaign=undefined">
										Smart Store+ </a></b>
										division at 
										<b><a href = "https://www.capillarytech.com/?searchkeyword=capillary%20technologies&matchtype=b&adposition=&device=c&locationID=1007809&utm_source=google&utm_medium=cpc&utm_campaign=Capillary_India_Brand&Lead_Source=Adwords%20PPC&gclid=Cj0KCQjwu7OIBhCsARIsALxCUaOusCbOHTtNEPyNMe_1kE69xKVe7hL0CAetZ5z4JLIYqJS2eRwtiVoaArWIEALw_wcB">
										Capillary Technologies Pvt Ltd.</a></b> <br><br>
										&ensp; &ensp; &ensp; &ensp;
										Previously, I was a Computer Vision Intern at Capillary Technologies and at an early stage 
										startup <b><a href = "http://sdtech.io/">SDTECH (Formely known as Studio Diseno)</a></b>. I started writting the blog 
										<a href="http://html5up.net">Machine Learning Cognitio</a> to solidfy my understanding 
										of computer vision and machine learning while helping others to learn about.										
									</header>
									<div class = "row">
										<div class="col">&ensp;</div>
									</div>
									<div class = "row">
										<div class="col-9">&ensp;</div>
										<div class="col">
											<div class="float-right"><a href="#" class="button icon solid fa-download">Resume</a></div>
											<!-- <div class="float-right"><a href="#" class="button primary icon solid fa-download">Resume</a></div> -->
										</div>											
									</div>									
								</div>
							</section>

						<!-- Skills -->
							<section id="skills">
								<div class="container" style = "text-align: justify;text-justify: inter-word;">
									<h3>Skills</h3>
									<p>Below are some of my skills, and I'am always looking to learn more.</p>

									<h5>Computer Vision</h5>
									<p >
										<span class="image left">
											<img src="images/computer_vision.jpeg" alt="" height="100" width = "100"/></span>
											I have signifcant research and industrial experience in developing Computer Vision applications
											using tools like <b>OpenCV</b>, <b>scikit-geometery</b> and <b>scikit-image</b> in C++ and Python. 
											The applications developed tested my knowledge on tradional computer vision, image processing  
											and computational geometery.											
									</p>									

									<h5>Machine Learning</h5>
									<p>
										<span class="image left">
											<img src="images/machine_learning.jpeg" alt="" height="100" width = "100"/></span>
											My typical day at work include developing machine learning applications using 
											<b>TensorFlow</b>, <b>Keras</b> and <b>scikit-learn</b>. Furthermore, I have performed data 
											manipulation, data analysis and visulization using tools like <b>pandas</b>, <b>matplotlib</b> and <b>seaborn</b>.
											I also have experience using <b>PySpark</b> for distributed data processing. 											
									</p>
									
									<h5>Python</h5>
									<p >
										<span class="image left">
											<img src="images/python.jpeg" alt="" height="100" width = "100"/></span>
											Over the past 5.5 years, I've had extensive experience with Python in the course of research, classwork, personal projects 
											and at work. The Machine Learning applications developed by me in Python have used <b>Object Oriented Programming (OOPs)</b> has it's
											programming paradigm and <b><a href="https://docs.python.org/3/library/typing.html">typing</a></b> as it's support for type hints. 
									</p>
									
									<h5>C++</h5>
									<p >
										<span class="image left">
											<img src="images/c_plus_plus.png" alt="" height="100" width = "100"/></span>
											My experience in C++ comes from developing computer vision applications for edge devices using OpenCV and practising 
											competative programming on platforms such as LeetCode, Hackerrank, Hackearth and InterviewBit. I have also compiled and 
											generated libraries using <b>cmake</b>.
									</p>
									
									<h5>AirFlow</h5>
									<p >
										<span class="image left">
											<img src="images/airflow.png" alt="" height="100" width = "100"/></span>
											I have used AirFlow as an Orchestration tool for <b>MLOps</b> to automate and managing workflows such as  
											data validation before training an AI model, training the machine learning model at specific intervals, batch processing,
											and inference. 
											  								
									</p>
									<br>
									<!-- <h5>PySpark</h5>
									<p >
										<span class="image left">
											<img src="images/pyspark.png" alt="" height="100" width = "100"/></span>
											I have signifcant research and industrial experience in developing Computer Vision applications
											using tools like <b>OpenCV</b> and <b>Scikit-Image</b> in C++ and Python. The applications developed by me
											include object tracking, face recognition, document detection, automating camera calibration 
											and many many more.											
									</p> -->

									<h5>TensorFlow</h5>
									<p >
										<span class="image left">
											<img src="images/tensorflow.png" alt="" height="100" width = "100"/></span>
											 I have a significant experience using TensorFlow for developing and training <b>deep neural networks (DNNs)</b> for 
											 computer vision applications. While working for Capillary, I have built custom layers and pruned DNNs for reducing the 
											 model complexity. Furthermore, I have <b>quantized deep neural networks</b> using <b>post training quantization</b> and 
											 <b>quantization aware training</b> for deploying models on edge devices.

									</p>									
									
									<h5>MongoDB</h5>
									<p >
										<span class="image left">
											<img src="images/mongodb.jpeg" alt="" height="100" width = "100"/></span>
											I have some experience of using MongoDB as backend database from developing machine learning applications, 
											all the applications use Python's MongoDB driver. Furthermore, I also have experience in utilizing the aggregate 
											framework provided by MongoDB for document transformation and data analysis.
									</p>

									<br>
									
									<h5>SQL</h5>
									<p >
										<span class="image left">
											<img src="images/SQL.png" alt="" height="100" width = "100"/></span>
											My experience in SQL comes from reading Capillary's massive database using PySpark to perform data validation, 
											and feature engineering	for creating the train, test and validation set for Machine Learning models.  										
									</p>									
									<br>
								</div>

							</section>

							<!-- Work Experience -->
							<section id="work_experience">
								<div class='container'>
									<ul style='list-style: circle; text-align: justify;'>
										<li>
											<p>April 2021 - Present</p>
											<div class = "">
												<h2>Machine Learning Engineer - II</h2>
												<h3>Capillary Technologies Pvt Ltd.</h3>	
												<h4>Work done so far:</h4>							
												<ul>
													<li style='margin-bottom: 15px;'>														
														<b>Automated the generation of fundamental matrix</b> using facial key points as it's correspondence
														coordinates between pair of images, each image in a pair taken from on of the two cameras having 
														different prespective views. <b>Reduced the camera calibration time from 1 hour to 5 mins for an Edge AI product (Customer Visual Profile).</b>
													</li>
													<li style='margin-bottom: 15px;'>
														Developed a <strong>segmentation algorithm</strong> using <strong>OpenPose (Deep Neural Network)</strong> and Watershed algorithm to 
														create segmentation maps to segment people in an image for <strong>edge computing</strong>.
													</li>
													<li style='margin-bottom: 15px;'>
														<!-- Developed workflow management pipeline using <strong>AirFlow</strong> to schedule data validation notebooks 
														hosted on DataBricks before training Machine Learing Models. -->
														Developed core orchestration service logic based on Directed Acyclic Graph (DAG) to schedule data validation notebooks hosted
														at DataBricks using <strong>AirFlow</strong>.
													</li>
												</ul>
												<h4>Responsibilities:</h4>
												<ul>
													<li>Lead the research and development of the POC for computer vision applications in SmartStore+ team.</li>
													<li>Mentoring interns and Junior Machine Learning Engineer, guiding them in their progress and overlooking the work distribution.</li>													
													<li>Ownership of maintaining and enhancing the data validation framework which is used to validate data before training machine learning models.</li>
												</ul>
												<h4>Technologies Used:</h4>												
												<p>TensorFlow, AirFlow, OpenCV, Python, PySpark</p>
											</div>
										</li>

										<li>
										<p>June 2019 - March 2021</p>
										<div class = "">
											<h2>Machine Learning Engineer - I</h2>
											<h3>Capillary Technologies Pvt Ltd.</h3>
											<h4>Work Done:</h4>
											<ul>
												<li style='margin-bottom: 15px;'>
													Developed an AI-product to calculate the customer's time spent (or Dwell time) in a store using two modules person re-identification and a matching algorithm. 
													<ul style="list-style-type: square; margin-bottom: 5px;">
														<li>The person re-identification is a deep learning model developed using <strong>ResNet-50 backend</strong> and a <strong>triplet loss objective function.</strong></li>
														<li>The matching of embedding generated using ResNet 50 model was done using <strong>Hungarian assignment</strong> as well as <strong>K-Nearest Neighbors</strong>.</li>
														<li>The model was served using <strong>TensorFlow serving</strong> on Amazon EIA.</li>														
													</ul>
												</li>

												<li style='margin-bottom: 15px;'>
													Developed two versions of badge classification model using deep learning models with <strong>MobileNetV1</strong> and <strong>MobileNetV2</strong> backend. The model selection
													was done using ROC and AUC metric. 
												</li>
												<li style='margin-bottom: 15px;'>
													Developed face recognition model with different deep learning backends namely <strong>ResNet101, MobileNetV2</strong> and <strong>ResNet50</strong> with arc-face has it's loss function.
												</li>
												<li style='margin-bottom: 15px;'>
													Performed <strong>post training quantization</strong> and <strong>quantization aware training</strong> on the above mentioned models to inference on edge devices such as Raspberry Pi, Google Coral Dev board and 
													Google Coral USB Accelerator using TensorFlow.
												</li>
												<li style='margin-bottom: 15px;'>
													Used <strong>Epipolar Geometery</strong> to assign the same visitor ID (UUID) to a customer detected in two cameras having two different prespective views. Furthermore, used <strong>Intersection Over Union (IOU)</strong> for eliminating 
													occluded customers on the edge device. 
												</li>
												<li style='margin-bottom: 15px;'>
													Developed a document detection algorithm to detect a document in an image for an OCR product. <strong>The document detection algorithm obtained 0.93 as it's Jaccard Index.</strong>													
												</li>
												<li style='margin-bottom: 15px;'>
													Performed <strong>Exploratory Data Analysis (EDA)</strong> on client's customer behaviour towards the loyalty program provided by Capillary Technologies Pvt Ltd.
												</li>												
											</ul>
											<h4>Responsibilities:</h4>
											<ul>
												<li>Mentoring interns and overlooking the work distribution.</li>													
												<li>Ownership of three AI micro-services and two device modules.</li>
											</ul>
											<h4>Technologies Used:</h4>												
											<p>TensorFlow, OpenCV, Python, Scikit-learn, Scipy</p>											
										</div>
										</li>
										
										<li>
											<p>January 2019 - May 2019</p>
											<div class = "">
												<h2>Computer Vision Intern</h2>
												<h3>Capillary Technologies Pvt Ltd.</h3>
												<h4>Work Done:</h4>
												<ul>
													<li style='margin-bottom: 15px;'>														
														<strong>Developed Revolver YOLO</strong>: Person detection algorithm for fish-eye lenses, traditional off the shelf deep learning models don't detect person which have been distorted i.e. roated due to 
														FOV being 360 degree or 280 degree. To counter this we rotate (using rotational matrix) equally intrevaled patches of the image and make it upright perform detection and rotate it back to it's original position.
													</li>
													<li style='margin-bottom: 15px;'>
														Developed a logic similar to background subtraction to discard mannequins detected as person by <strong>YOLO</strong>. 
													</li>
													<li>
														Developed YOLO-Lite in TensorFlow from scratch and trained the model using an in-house dataset for person detection. The model performance was 21 mAP for the test set and gave 5 FPS on Raspberry Pi 3 B+. 
													</li>
												</ul>																								
											
												<h4>Technologies Used:</h4>
												<p>OpenCV, TensorFlow, Python, C++</p>
											</div>											
										</li>										
									</ul>
								</div>
							</section>			

							<!-- Research Papers -->
							<section id="research_papers">
								<div class="container">
									<h3>Research Papers</h3>
									<div class="row">
										<ol>										
											<li>
												<header>
													<h4>EarNet: Biometric Embeddings for End to End Person Authentication System Using Transient Evoked Otoacoustic Emission Signal</h4>
													<p>Journal: Neural Processing Letters | Springer | Status: Paper Accepted</p>
												</header>
												<p style='text-align: justify;'>
													Transient Evoked Otoacoustic Emissions (TEOAE) are a class of otoacoustic emissions 
													that are generated by the cochlea in response to an external													
													stimulus. The TEOAE signals exhibit characteristics unique to an individual, and
													are therefore considered as a potential biometric modality. Unlike conventional													
													modalities, TEOAE is immune to replay and falsification attacks due to its implicit liveliness detection feature. In this paper, we propose an efficient deep neural													
													network architecture, EarNet, to learn the appropriate filters for non-stationary													
													(TEOAE) signals, which can reveal individual uniqueness and long-term reproducibility. EarNet is inspired by Googleâ€™s FaceNet. Furthermore, the embeddings													
													generated by EarNet, in the Euclidean space, are such that they reduce intrasubject variability while capturing inter-subject variability, as visualized using													
													t-SNE. The embeddings from EarNet are used for identification and verification
													tasks. The K-Nearest Neighbour classifier gives <b>identification accuracies of 99.21%
													and 99.42% for the left and right ear</b>, respectively, which are highest among the
													machine learning algorithms explored in this work. The verification using Pearson
													correlation on the embeddings performs with an <b>EER of 0.581% and 0.057% for
													the left and right ear</b>, respectively, scoring better than all other techniques. <b>Fusion
													strategy yields an improved identification accuracy of 99.92%</b>. The embeddings
													generalize well on subjects that are not part of the training, and hence EarNet is
													scalable on any new larger dataset.
												</p>
											</li>
											<li>
												<header>
													<h4>H. U. B - Eye, Hearing using Bone Conduction and seeing through DNN</h4>
													<p>Conference: International Conference on Advanced Computing and Communications (ADCOM 2018)</p>
												</header>
												<p style='text-align: justify;'>
													The paper proposes a device capable of making the
													lives of visually impaired easier. The device encompasses an image
													recognition using deep learning (convolutional neural network)
													unit coupled with the novel idea of the bone conduction system,
													which can be mounted on the sunglasses of the visually impaired.
													The whole process allows two-channel hearing enabling people
													to hear regular as well as the intended audio. Instead of air, the
													sound is propagated through the bone in the form of vibration
													and is sent to cochlea through a membrane. The proposed
													system takes an image from a mounted camera, classifies it
													with a dedicated processor and sends the audio signal through a
													Bluetooth channel to the bone conduction transducer so that the
													user can hear through the system what is in front of him. The
													system is able to recognize the input image using deep learning
													and give an audio output directly to the eardrum of the user.
												</p>
											</li>										
										</ol>
									</div>
								</div>
							</section>	
							
							<!-- Education -->
							<section id="education">
								<div class="container">
									<h3>Education</h3>
									<div class="features">
										<article>
											<a href="#" class="image"><img src="images/vit_full.png" alt="" /></a>
											<div class="inner">
												<h4>Vellore Institute of Technology, Chennai</h4>
												<p>
													MTech Integrated in Software Engineering <br>
													(5 years program)<br>
													CGPA: 9.32/10.0
												</p>
											</div>
										</article>
										<p style='text-align: justify;'>
											My education in Software Engineering focused from strong software engineering princeples such as SDLC, Software Requirement Specificatin (SRS), Requirement Specification Document etc. to 
											good programming practices in Python, C++, JAVA, .NET and Computer Networks. Furthermore, we had vigrous courses on Data Structures &#38; Algorithms, Linear Algebra, Probability &#38; Statistics 
											and Calculus. 
										</p>

										<p style='text-align: justify;'>
											My extra curricular activities during my college days included participating in various Hackathons and IOT Makeathons. I also lead Technocrats Robotics Team in the year 2018 to Robocon 2018 competition. 
											Few, my work in the team are presented in this vido clips shown below. 
										</p>
									</div>
								</div>
							</section>
							
						<!-- Accomplishments -->
							<section id="accomplishments">
								<div class="container">
									<h3>Accomplishments</h3>
									<p>A few of my notable accomplishments are given below,</p>
									<div class="features">
										<article>
											<a href="#" class="image"><img src="images/pic01.jpg" alt="" /></a>
											<div class="inner">
												<h4>Possibly broke spacetime</h4>
												<p>Integer eu ante ornare amet commetus vestibulum blandit integer in curae ac faucibus integer adipiscing ornare amet.</p>
											</div>
										</article>
										<article>
											<a href="#" class="image"><img src="images/pic02.jpg" alt="" /></a>
											<div class="inner">
												<h4>Terraformed a small moon</h4>
												<p>Integer eu ante ornare amet commetus vestibulum blandit integer in curae ac faucibus integer adipiscing ornare amet.</p>
											</div>
										</article>
										<article>
											<a href="#" class="image"><img src="images/pic03.jpg" alt="" /></a>
											<div class="inner">
												<h4>Snapped dark matter in the wild</h4>
												<p>Integer eu ante ornare amet commetus vestibulum blandit integer in curae ac faucibus integer adipiscing ornare amet.</p>
											</div>
										</article>
									</div>
								</div>
							</section>

						<!-- Hobbies -->
							<section id="hobbies">
								<div class="container">
									<h3>Hobbies</h3>
									<p style='text-align: justify;'>
										<span class="image left"><img src="images/tennis.jpg" alt="" width = "300px" height="300px"/></span>
										Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum 
										primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer 
										ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. 
										Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent. 
										Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus 
										vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent 
										tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis 
										iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent.
									</p>

									<p style='text-align: justify;'>
										<span class="image right"><img src="images/chess.png" alt="" width = "300px" height="400px"/></span>
										Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum 
										primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer 
										ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. 
										Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent. Donec 
										accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus 
										vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent
										 tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu 
										 felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent.
									</p>
								</div>
							</section>
				
					</div>

				<!-- Footer -->
					<section id="footer">
						<div class="container">
							<ul class="copyright">
								<li>&copy; Akshath Varugeese. All rights reserved.</li>
							</ul>
						</div>
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>